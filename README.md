# Swiggy_Data_Cleaning_Using_SQL

## Project Overview
This project focuses on cleaning and preprocessing raw Swiggy order data using SQL.
The main goal was to transform messy and inconsistent data into a structured and reliable format ready for analysis.

***Key Objectives***

 1. Detect and handle missing and duplicate values

 2. Standardize text and numeric fields (e.g., city names, prices, delivery times)

 3. Split and extract useful data using string functions

 4. Use joins and subqueries to merge and cross-check data

 5. Apply filters and conditions to remove invalid or outlier records

***SQL Concepts Used***

  1. Joins (INNER JOIN, LEFT JOIN)
  
  2. Subqueries and CTEs
  
  3. String functions: REPLACE(), SUBSTRING_INDEX(), TRIM(), LOWER(), etc.
  
  4. Aggregate functions: COUNT(), AVG(), MAX()
  
  5. Filtering with wildcards: LIKE, NOT LIKE
  
  6. Temporary Tables / Views


***Key Learnings***

 - Strengthened SQL skills for real-world data wrangling

- Learned systematic data validation using SQL queries

- Understood how to structure SQL-based data cleaning pipelines

***How to Run This Project***

  1. Download the .sql and .csv files

  2. Import the dataset into your SQL environment (MySQL / PostgreSQL)

  3. Run data_cleaning_queries.sql sequentially

  4. Verify the output with SELECT * FROM swiggy_cleaned;
